**Distillation of random tips**
- read recent papers in research area to get an understanding of the current problems and how to communicate it with the intended audience (authors of those papers)
- reproduce results of those papers and then implement their method for data you're interested in
- do the data science dirty work to make sure there is no stone unturned for end-to-end understanding of research solutions
- doing the above 3 things ensures that we'll make opinions about the problem, "which can result in a workable idea"
- ambitions for any research product is to produce ML papers that could in theory be highly judged by a NIPS-like mindset... from their guidelines: ML papers will be judged on at least five criteria: (1) novelty of algorithm, e.g., a new and elegant derivation for an algorithm or a new approach to an existing problem; (2) novelty of the application or problem, e.g., one that introduces a novel ML problem like ICA and structured prediction and that proposes an algorithm for it; (3) difficulty of the application, e.g., an application of ML to a difficult, important, and "real" application that takes into account the full complexity of getting a non-trivial system to work; (4) quality of results; (5) insight conveyed, e.g., whether paper conveys insight into the nature of an algo, the nature of a practical application or problem, or that conveys general lessons and theoretical or mathematical tools that will be used by others in future work

# References
1. [summary](https://www.quora.com/How-can-I-publish-papers-in-NIPS-ICML-AAAI-IJCAI-I-dont-know-how-to-get-the-novel-ideas) of Andrew Ng's lecture
2. Guidelines for writing a good NIPS paper, published in 2015 (see [here](https://nips.cc/Conferences/2015/PaperInformation/EvaluationCriteria))
3. Richard Hamming's bro-y recommendations (see "You and Your Research, [here](https://www.cs.virginia.edu/~robins/YouAndYourResearch.html))
4. Hannah Arendt
